{
    "collab_server" : "",
    "contents" : "#Truncated distribution function\n\n#One-hurdle likelihood:\n\n#                 {   p,                            yi = 0\n#    Yi|theta =   {\n#                 {   (1-p)*f(x|theta),             yi > 0\n\n#Two-hurdle liklihood:\n\n#                 {   p,                            yi = 0\n#                 {\n#    Yi|theta =   {   (1-q)*(1-p)*f(x|theta),       0 < yi < psi\n#                 {\n#                 {   q*(1-p)*g(x|theta),           yi >= psi\n\nfile.sources = list.files(\"F:/Balderama/hurdlr/R\",\n                          pattern = \"*.R$\", full.names = TRUE,\n                          ignore.case = TRUE)\nsapply(file.sources, source, .GlobalEnv)\n\n#MCMC start\nhurdle <- function(y, x = NULL, hurd = Inf,\n                   dist = c(\"poisson\", \"nb\", \"lognormal\", \"gpd\"),\n                   dist.2 = c(\"none\", \"gpd\", \"poisson\", \"lognormal\", \"nb\"),\n                   control = hurdle_control(),\n                   iters = 1000, burn = 500, nthin = 1,\n                   plots = T, progress.bar = T){\n\n  #Initial values\n  N <- length(y)\n  hurd <- ifelse(dist.2 == \"none\", Inf, hurd)\n  pb <- txtProgressBar(min = 0, max = iters, style = 3)\n  x <- cbind(rep(1, N), X)\n  x <- as.matrix(x)\n  x.col <- ncol(x)\n  regressions <- 3\n  out.fx <- out.gx <- out.probs <- NULL\n\n  beta <- matrix(0, x.col, regressions)\n  XB1 <- c(x%*%beta[,1])\n  XB2 <- c(x%*%beta[,2])\n  XB3 <- c(x%*%beta[,3])\n\n  lam <- mu <- sigma <- exp(XB1)\n  xi <- control$xi.start\n  p <- 1/(1 + exp(-XB2))\n  q <- 1/(1 + exp(-XB3))\n\n  #Priors\n  a <- control$a\n  b <- control$b\n  size <- control$size\n  beta.prior.mean <- control$beta.prior.mean\n  beta.prior.sd <- control$beta.prior.sd\n\n  #Tuning\n  beta.tune <- matrix(rep(c(control$pars.tune, rep(control$probs.tune, 2)), each = x.col), x.col, regressions)\n  beta.acc <- matrix(0, x.col, regressions)\n  att <- 0\n\n  #Keep vectors\n  keep.beta <- array(0, c(iters, x.col, regressions))\n  keep.pars <- NULL\n\n  #Diagnostics\n  keep.dev <- track.ppo <- track.icpo <- 0\n\n  #If using a two-hurdle model\n  if(hurd != Inf){\n\n    #Initial values\n    lam2 <- control$lam.start\n    mu2 <- control$mu.start\n    xi2 <- control$xi.start\n    sigma2 <- control$sigma.start\n\n    #Tuning\n    lam2.tune <- mu2.tune <- xi2.tune <- sigma2.tune <- control$pars.tune\n    lam2.acc <- mu2.acc <- xi2.acc <- sigma2.acc <- 0\n\n    #Keep vectors\n    keep.pars <- matrix(0, iters, 4)\n  }\n\n\n  #Likelihood\n  pZ <- PZ(p[y == 0], log = T)\n  pT <- PT(p[0 < y & y < hurd], q[0 < y & y < hurd], log = T)\n  LT <- dist_ll(y = y[0 < y & y < hurd], hurd = hurd, size = size,\n                lam = lam[0 < y & y < hurd], mu = mu[0 < y & y < hurd],\n                xi = xi, sigma = sigma[0 < y & y < hurd], dist = dist, g.x = F, log = T)\n  pE <- PE(p[y >= hurd], q[y >= hurd], log = T)\n  LE <- dist_ll(y = y[y >= hurd], hurd = hurd, size = size,\n                lam = control$lam.start, mu = control$mu.start,\n                xi = xi, sigma = control$sigma.start, dist = dist.2, g.x = T, log = T)\n  ll <- NULL\n  ll[y == 0] <- pZ\n  ll[0 < y & y < hurd] <- pT + LT\n  ll[y >= hurd] <- pE + LE\n\n  for(i in 2:iters){\n    for(thin in 1:nthin){\n\n      att <- att + 1\n\n      #Update f(x) parameters\n      out.fx <- update_beta(y = y[0 < y & y < hurd], x[which(0 < y & y < hurd),],\n                            hurd, dist = dist, like.part = LT,\n                            beta.prior.mean, beta.prior.sd,\n                            beta, XB1[0 < y & y < hurd], beta.acc, beta.tune,\n                            g.x = F)\n\n      if(dist == \"poisson\"){\n        beta[,1] <- out.fx$beta1; beta.acc[,1] <- out.fx$beta1.acc\n        XB1 <- x%*%beta[,1]\n        lam <- exp(XB1)\n      }\n\n      if(dist == \"nb\" | dist == \"lognormal\"){\n        beta[,1] <- out.fx$beta1; beta.acc[,1] <- out.fx$beta1.acc\n        XB1 <- x%*%beta[,1]\n        mu <- exp(XB1)\n      }\n\n      if(dist == \"gpd\"){\n        beta[,1] <- out.fx$beta1; beta.acc[,1] <- out.fx$beta1.acc\n        XB1 <- x%*%beta[,1]\n        sigma <- exp(XB1)\n      }\n\n      LT <- dist_ll(y = y[0 < y & y < hurd], hurd = hurd, size = size,\n                    lam = lam[0 < y & y < hurd], mu = mu[0 < y & y < hurd], xi = xi,\n                    sigma = sigma[0 < y & y < hurd], dist = dist, g.x = F, log = T)\n\n\n      if(hurd != Inf){\n\n        #Update g(x) parameters\n        out.gx <- update_pars(y = y[y >= hurd], hurd,\n                              dist = dist.2, like.part = LE,\n                              a, b, size, lam2, mu2, xi2, sigma2,\n                              lam2.acc, mu2.acc, xi2.acc, sigma2.acc,\n                              lam2.tune, mu2.tune, xi2.tune, sigma2.tune,\n                              g.x = T)\n        if(dist.2 == \"poisson\"){\n          lam2 <- out.gx$lam; lam2.acc <- out.gx$lam.acc\n        }\n\n        if(dist.2 == \"nb\" | dist.2 == \"lognormal\"){\n          mu2 <- out.gx$mu; mu2.acc <- out.gx$mu.acc\n        }\n\n        if(dist.2 == \"gpd\"){\n          xi2 <- out.gx$xi; xi2.acc <- out.gx$xi.acc\n          sigma2 <- out.gx$sigma; sigma2.acc <- out.gx$sigma.acc\n        }\n\n        LE <- dist_ll(y = y[y >= hurd], hurd = hurd, size = size,\n                      lam = lam2, mu = mu2, xi = xi2,\n                      sigma = sigma2, dist = dist.2, g.x = T, log = T)\n      }\n\n      out.probs <- update_probs(y, x, hurd, p, q,\n                                beta.prior.mean, beta.prior.sd,\n                                pZ, pT, pE,\n                                beta, XB2, XB3, beta.acc, beta.tune)\n\n      beta[,2] <- out.probs$beta2; beta.acc[,2] <- out.probs$beta2.acc\n      XB2 <- x%*%beta[,2]\n      p <- 1/(1 + exp(-XB2))\n\n      beta[,3] <- out.probs$beta3; beta.acc[,3] <- out.probs$beta3.acc\n      XB3 <- x%*%beta[,3]\n      q <- 1/(1 + exp(-XB3))\n\n      #Update likelihood\n      pZ <- PZ(p[y == 0], log = T)\n      pT <- PT(p[0 < y & y < hurd], q[0 < y & y < hurd], log = T)\n      pE <- PE(p[y >= hurd], q[y >= hurd], log = T)\n\n      ll[y == 0] <- pZ\n      ll[0 < y & y < hurd] <- pT + LT\n      ll[y >= hurd] <- pE + LE\n\n\n    }#End thinning\n\n    keep.dev[i] <- -2*sum(ll)\n    keep.beta[i,,] <- beta\n\n    if(hurd != Inf){\n      keep.pars[i,] <- c(lam2, mu2, sigma2, xi2)\n    }\n\n    if(i > burn){\n      track.ppo <- track.ppo + exp(ll)\n      track.icpo <- track.icpo + 1/exp(ll)\n    }\n\n    #Update tuning parameters\n    if(i < 0.75*burn & att > 50){\n\n      for(k in 1:regressions){\n        beta.tune[,k] <- ifelse(beta.acc[,k]/att < 0.20, 0.8*beta.tune[,k], beta.tune[,k])\n        beta.tune[,k] <- ifelse(beta.acc[,k]/att > 0.50, 1.2*beta.tune[,k], beta.tune[,k])\n      }\n\n      beta.acc <- matrix(0, x.col, regressions)\n\n      if(hurd != Inf){\n        lam2.tune <- ifelse(lam2.acc/att < 0.20, 0.8*lam2.tune, lam2.tune)\n        lam2.tune <- ifelse(lam2.acc/att > 0.50, 1.2*lam2.tune, lam2.tune)\n        mu2.tune <- ifelse(mu2.acc/att < 0.20, 0.8*mu2.tune, mu2.tune)\n        mu2.tune <- ifelse(mu2.acc/att > 0.50, 1.2*mu2.tune, mu2.tune)\n        xi2.tune <- ifelse(xi2.acc/att < 0.20, 0.8*xi2.tune, xi2.tune)\n        xi2.tune <- ifelse(xi2.acc/att > 0.50, 1.2*xi2.tune, xi2.tune)\n        sigma2.tune <- ifelse(sigma2.acc/att < 0.20, 0.8*sigma2.tune, sigma2.tune)\n        sigma2.tune <- ifelse(sigma2.acc/att > 0.50, 1.2*sigma2.tune, sigma2.tune)\n\n        lam2.acc <- mu2.acc <- xi2.acc <- sigma2.acc <- 0\n      }\n      att <- 0\n    }\n\n    #Plots\n    if(plots == T){\n\n      if(i > burn & i%%200 == 0){\n\n        num.plots <- ifelse(hurd != Inf, par(mfrow = c(2,3)), par(mfrow = c(1,3))); num.plots\n        plot(keep.beta[burn:i,1,1], type = \"l\",\n             ylab = \"\", main = bquote(beta[0]~Typical~Mean))\n        abline(h = mean(keep.beta[burn:i,1,1]), col = 2)\n        plot(keep.beta[burn:i,1,2], type = \"l\",\n             ylab = \"\", main = bquote(beta[0]~Zero~Prob))\n        abline(h = mean(keep.beta[burn:i,1,2]), col = 2)\n\n        if(hurd != Inf){\n\n          plot(keep.beta[burn:i,1,3], type = \"l\",\n               ylab = \"\", main = bquote(beta[0]~Extreme~Prob))\n          abline(h = mean(keep.beta[burn:i,1,3]), col = 2)\n\n          if(dist.2 == \"poisson\"){\n            plot(keep.pars[burn:i,1], type = \"l\",\n                 ylab = \"\", main = bquote(Extreme~Mean~lambda))\n            abline(h = mean(keep.pars[burn:i,1]), col = 2)\n          }\n\n          if(dist.2 == \"nb\" | dist.2 == \"lognormal\"){\n            plot(keep.pars[burn:i,2], type = \"l\",\n                 ylab = \"\", main = bquote(Extreme~Mean~mu))\n            abline(h = mean(keep.pars[burn:i,2]), col = 2)\n          }\n\n          if(dist.2 == \"gpd\"){\n            plot(keep.pars[burn:i,4], type = \"l\",\n                 ylab = \"\", main = bquote(xi[gpd]))\n            abline(h = mean(keep.pars[burn:i,4]), col = 2)\n            plot(keep.pars[burn:i,3], type = \"l\",\n                 ylab = \"\", main = bquote(sigma[gpd]))\n            abline(h = mean(keep.pars[burn:i,3]), col = 2)\n          }\n        }\n\n        plot(burn:i, keep.dev[burn:i], type=\"l\",\n             ylab = \"\", xlab = \"Index\", main = bquote(D==-2*sum(loglike)))\n        abline(h = mean(keep.dev[burn:i]), col = 2)\n      }\n    }\n\n    if(progress.bar){setTxtProgressBar(pb, i)}\n\n  }#End loop\n\n\n  #Diagnostics (plots, pD, DIC)\n  beta.bar <- apply(array(keep.beta[(burn):iters,,], c(iters-burn, x.col, regressions)), 2:3, mean)\n\n  XB1 <- c(x%*%beta.bar[,1])\n  XB2 <- c(x%*%beta.bar[,2])\n  XB3 <- c(x%*%beta.bar[,3])\n\n  typ.mean.bar <- pz.bar <- pe.bar <- NULL\n  typ.mean.bar <- exp(XB1)\n  pz.bar <- 1/(1 + exp(-XB2))\n  pe.bar <- 1/(1 + exp(-XB3))\n\n  if(hurd != Inf){\n    ext.lam.bar <- mean(keep.pars[burn:i,1])\n    ext.mu.bar <- mean(keep.pars[burn:i,2])\n    ext.sigma.bar <- mean(keep.pars[burn:i,3])\n    ext.xi.bar <- mean(keep.pars[burn:i,4])\n  }\n\n  PZ.bar <- PT.bar <- PE.bar <- LT.bar <- LE.bar <- NULL\n  PZ.bar <- PZ(pz.bar[y == 0], log = T)\n  PT.bar <- PT(pz.bar[0 < y & y < hurd], pe.bar[0 < y & y < hurd], log = T)\n  PE.bar <- PE(pz.bar[y >= hurd], pe.bar[y >= hurd], log = T)\n  LT.bar <- dist_ll(y[0 < y & y < hurd], hurd = hurd,\n                    lam = typ.mean.bar, mu = typ.mean.bar,\n                    dist = dist, g.x = F, log = T)\n\n  ll.means <- c(PZ.bar, PT.bar, LT.bar)\n\n  if(hurd != Inf){\n    LE.bar <- dist_ll(y[y > hurd], hurd = hurd,\n                      lam = ext.lam.bar, mu = ext.mu.bar,\n                      sigma = ext.sigma.bar, xi = ext.xi.bar,\n                      dist = dist.2, g.x = T, log = T)\n\n    ll.means <- c(PZ.bar, PT.bar, PE.bar, LT.bar, LE.bar)\n  }\n\n  #pD (effective # of parameters) = mean deviance - deviance at posterior means\n  pD <- mean(keep.dev[(burn + 1):iters]) - (-2*sum(ll.means))\n\n  #DIC = mean deviance + pD\n  DIC <- mean(keep.dev[(burn + 1):iters]) + pD\n\n\n  ll.means <- list(PZ.bar = PZ.bar, PT.bar = PT.bar, LT.bar = LT.bar)\n  pars.means <- list(typ.mean.bar = typ.mean.bar, pz.bar = pz.bar)\n  beta.means <- list(typ.mean = beta.bar[,1], pz = beta.bar[,2])\n\n  if(hurd != Inf){\n\n    if(dist.2 == \"poisson\"){\n      pars.means <- list(typ.mean.bar = typ.mean.bar, pz.bar = pz.bar,\n                         pe.bar = pe.bar, ext.lam.bar = ext.lam.bar)\n    }\n\n    if(dist.2 == \"nb\" | dist.2 == \"lognormal\"){\n      pars.means <- list(typ.mean.bar = typ.mean.bar, pz.bar = pz.bar,\n                         pe.bar = pe.bar, ext.mu.bar = ext.mu.bar)\n    }\n\n    if(dist.2 == \"gpd\"){\n      pars.means <- list(typ.mean.bar = typ.mean.bar, pz.bar = pz.bar,\n                         pe.bar = pe.bar, ext.sigma.bar = ext.sigma.bar, ext.xi.bar = ext.xi.bar)\n    }\n\n    ll.means <- list(PZ.bar = PZ.bar, PT.bar = PT.bar, PE.bar = PE.bar,\n                     LT.bar = LT.bar, LE.bar = LE.bar)\n    beta.means <- list(typ.mean = beta.bar[,1], pz = beta.bar[,2], pe = beta.bar[,3])\n  }\n\n  #Keep betas\n  if(hurd == Inf){\n    keep.beta <- keep.beta[,,-3]\n  }\n\n\n  output <- list(pD = pD,\n                 DIC = DIC,\n                 PPO = track.ppo/(iters - burn),\n                 CPO = (iters - burn)/(track.icpo),\n                 pars.means = pars.means,\n                 ll.means = ll.means,\n                 beta.means = beta.means,\n                 dev = keep.dev[(burn + 1):iters],\n                 beta = keep.beta[(burn + 1):iters,,],\n                 pars = keep.pars[(burn + 1):iters,]\n  )\n  return(output)\n}\n",
    "created" : 1478540405370.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1785411897",
    "id" : "6E118770",
    "lastKnownWriteTime" : 1473968524,
    "last_content_update" : 1473968524,
    "path" : "C:/Users/trium/Documents/Balderama/hurdlr/R/hurdle.R",
    "project_path" : null,
    "properties" : {
        "source_window_id" : "w0vx4w90lrfb3"
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}